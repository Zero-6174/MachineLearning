{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a95ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b4ecbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1340</td>\n",
       "      <td>313000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>3650</td>\n",
       "      <td>2384000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1930</td>\n",
       "      <td>342000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1940</td>\n",
       "      <td>550000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms  sqft_living    price\n",
       "0         3         1340   313000\n",
       "1         5         3650  2384000\n",
       "2         3         1930   342000\n",
       "3         3         2000   420000\n",
       "4         4         1940   550000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('house_price_full.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3d5ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.copy()\n",
    "y = X.pop('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b66cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardise the features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# perform log transform of target variable\n",
    "Y = np.log(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7956fd25",
   "metadata": {},
   "source": [
    "### Fast Forward for Single Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "724aaa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.433198</td>\n",
       "      <td>-0.753258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.675735</td>\n",
       "      <td>1.457330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.433198</td>\n",
       "      <td>-0.188649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.433198</td>\n",
       "      <td>-0.121661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.621269</td>\n",
       "      <td>-0.179079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.621269</td>\n",
       "      <td>0.873582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1.675735</td>\n",
       "      <td>2.299459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>-0.433198</td>\n",
       "      <td>-0.724549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>-0.433198</td>\n",
       "      <td>-0.179079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>-0.433198</td>\n",
       "      <td>-1.040347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1\n",
       "0   -0.433198 -0.753258\n",
       "1    1.675735  1.457330\n",
       "2   -0.433198 -0.188649\n",
       "3   -0.433198 -0.121661\n",
       "4    0.621269 -0.179079\n",
       "..        ...       ...\n",
       "494  0.621269  0.873582\n",
       "495  1.675735  2.299459\n",
       "496 -0.433198 -0.724549\n",
       "497 -0.433198 -0.179079\n",
       "498 -0.433198 -1.040347\n",
       "\n",
       "[499 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled = pd.DataFrame(X)\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc2da27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking 1 sample\n",
    "x1, x2 = df_scaled.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5d6cf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-07 16:14:28.710007: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#create random weight and bias\n",
    "#bias\n",
    "b = tf.Variable([0.1], dtype=tf.float32)\n",
    "\n",
    "#weights\n",
    "w1 = tf.Variable([0.2], dtype=tf.float32)\n",
    "w2 = tf.Variable([0.15], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f083137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of the first neuron is  tf.Tensor([0.47511354], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "h = (w1*x1 + w2*x2) + b\n",
    "z = tf.sigmoid(h)\n",
    "print(\"The output of the first neuron is \", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625b804d",
   "metadata": {},
   "source": [
    "### Fowrard propogation with multiple neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c17420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neuron1\n",
    "b1 = tf.Variable([0.1], dtype=tf.float32)\n",
    "w11 = tf.Variable([0.2], dtype=tf.float32)\n",
    "w12 = tf.Variable([0.15], dtype=tf.float32)\n",
    "\n",
    "#neuron2\n",
    "b2 = tf.Variable([0.25], dtype=tf.float32)\n",
    "w21 = tf.Variable([0.5], dtype=tf.float32)\n",
    "w22 = tf.Variable([0.6], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cfd7f7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output from the first neuron is tf.Tensor([0.47511354], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Forward pass\n",
    "#neuron1\n",
    "z1 = b1 + (w11 * x1 + w12 * x2)\n",
    "h1 = tf.math.sigmoid(z1)\n",
    "print(\"The output from the first neuron is\",h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92e8ee9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output from the second neuron is tf.Tensor([0.39686295], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#neuron2\n",
    "z2 = b2 + (w21 * x1 + w22 * x2)\n",
    "h2 = tf.math.sigmoid(z2)\n",
    "print(\"The output from the second neuron is\", h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d4d7ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer2 weights and bias\n",
    "b1 = tf.Variable([0.4])\n",
    "w11 = tf.Variable([0.3])\n",
    "w12 = tf.Variable([0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "818c60c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output from the first neuron is tf.Tensor([0.62190664], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Forward pass\n",
    "#neuron1\n",
    "\n",
    "z1 = b1 + (w11 * h1 + w12 * h2)\n",
    "h1 = z1\n",
    "print(\"The output from the first neuron is\", h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1fd8ca7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE error is  [72.38514]\n"
     ]
    }
   ],
   "source": [
    "y_actual = Y[0]\n",
    "y_pred = h1.numpy()\n",
    "\n",
    "L = 0.5 * (y_actual - y_pred) ** 2\n",
    "print(\"The MSE error is \", L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c7b14c",
   "metadata": {},
   "source": [
    "### Forward propogation with matrix multiplicaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13829f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layer 1 weight and Bias\n",
    "W1 = tf.Variable([[0.2, 0.15],\n",
    "                  [0.5, 0.6]])\n",
    "\n",
    "B1 = tf.Variable([[0.1],\n",
    "                  [0.25]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e555cdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 2 Weights and Bias\n",
    "W2 = tf.Variable([[0.3, 0.2]])\n",
    "\n",
    "B2 = tf.Variable([[0.4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eda3cab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.constant([[x1, x2]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2927cff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.47511354]\n",
      " [0.39686295]], shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "Z1 = tf.add(tf.matmul(W1, tf.transpose(X)), B1)\n",
    "H1 = tf.math.sigmoid(Z1)\n",
    "print(H1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8dfe521a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.62190664]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "Z2 = tf.matmul(W2, H1) + B2\n",
    "print(Z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bfaebada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72.38514]]\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = Z2.numpy()\n",
    "loss = 0.5 * (y_actual - y_pred2) ** 2\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49df4dd2",
   "metadata": {},
   "source": [
    "### Random Weight Initilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "817da8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_random_weight():\n",
    "    w1 = tf.Variable(tf.random.uniform(shape=(2, 2)))\n",
    "    b1 = tf.Variable(tf.random.uniform(shape=(2, 1)))\n",
    "    w2 = tf.Variable(tf.random.uniform(shape=(1, 2)))\n",
    "    b2 = tf.Variable(tf.random.uniform(shape=(1, 1)))   \n",
    "    \n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3f2819bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1, w2, b2 = init_random_weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e2a5e467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the initial 1st layer weights is  [[0.97680914 0.9927825 ]\n",
      " [0.8293736  0.4609152 ]]\n",
      "----------------------------------\n",
      "the initial 1st layer bias is  [[0.40270472]\n",
      " [0.11293721]]\n",
      "----------------------------------\n",
      "the initial 2nd layer weights is  [[0.9935589  0.07338095]]\n",
      "----------------------------------\n",
      "the initial 2nd layer bias is  [[0.32278013]]\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"the initial 1st layer weights is \", w1.numpy())\n",
    "print(\"----------------------------------\")\n",
    "print(\"the initial 1st layer bias is \",    b1.numpy())\n",
    "print(\"----------------------------------\")\n",
    "print(\"the initial 2nd layer weights is \", w2.numpy())\n",
    "print(\"----------------------------------\")\n",
    "print(\"the initial 2nd layer bias is \",    b2.numpy())\n",
    "print(\"----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5b472842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(x, w1, b1, w2, b2):\n",
    "    z1 = tf.matmul(w1, tf.transpose(x)) + b1\n",
    "    h1 = tf.math.sigmoid(z1)\n",
    "    z2 = tf.matmul(w2, z1) + b2\n",
    "    h2 = z2\n",
    "    \n",
    "    return h2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "82786bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[x1, x2]], dtype=tf.float32)\n",
    "y = Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b3f601cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = forward_prop(x, w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "53ff9fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE error is  [[71.336624]]\n"
     ]
    }
   ],
   "source": [
    "loss = 0.5 * (y_actual - y_pred3) ** 2\n",
    "print(\"The MSE error is \", loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4219767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd503b06",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "Find the value of x that minimises $y = x^2+4x$\n",
    "\n",
    "Gradient descent update equation\n",
    "\n",
    "$x_{new} := x_{old}-\\eta\\frac{dy}{dx}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8074865b",
   "metadata": {},
   "source": [
    "### Autogradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "05e0ad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable([0.0], dtype=tf.float32)\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4787860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example: how to use dx/dy using tensorflow\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x ** 2 + 4 * x\n",
    "\n",
    "grad = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9018909d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "57782dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(1,) dtype=float32, numpy=array([-0.4], dtype=float32)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.assign_sub(lr * grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8e0b9b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.4], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "78fa591e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4]\n",
      "[-0.72]\n",
      "[-0.9760001]\n",
      "[-1.1808001]\n",
      "[-1.34464]\n",
      "[-1.4757121]\n",
      "[-1.5805696]\n",
      "[-1.6644557]\n",
      "[-1.7315645]\n",
      "[-1.7852516]\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([0.0], dtype=tf.float32)\n",
    "lr = 0.1\n",
    "for i in range(10):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y = x ** 2 + 4 * x\n",
    "\n",
    "    grad = tape.gradient(y, x)\n",
    "    x.assign_sub(lr * grad)\n",
    "    print(x.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2d01b2",
   "metadata": {},
   "source": [
    "### Backpropagation for Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f5bf5025",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[x1, x2]], dtype=tf.float32)\n",
    "y = Y[0]\n",
    "lr = 0.01\n",
    "\n",
    "def init_random_weight():\n",
    "    w1 = tf.Variable(tf.random.uniform(shape=(2, 2)))\n",
    "    b1 = tf.Variable(tf.random.uniform(shape=(2, 1)))\n",
    "    w2 = tf.Variable(tf.random.uniform(shape=(1, 2)))\n",
    "    b2 = tf.Variable(tf.random.uniform(shape=(1, 1)))   \n",
    "    \n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "def forward_prop(x, w1, b1, w2, b2):\n",
    "    z1 = tf.matmul(w1, tf.transpose(x)) + b1\n",
    "    h1 = tf.math.sigmoid(z1)\n",
    "    z2 = tf.matmul(w2, z1) + b2\n",
    "    h2 = z2\n",
    "    \n",
    "    return h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9380cbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1, w2, b2 = init_random_weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "04bbeab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    y_pred = forward_prop(x, w1, b1, w2, b2)\n",
    "    loss = 0.5 * (y - y_pred) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "77c1786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gw1, gb1, gw2, gb2 = tape.gradient(loss, [w1, b1, w2, b2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7e01bf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gw1:  [[1.2130749  2.1093323 ]\n",
      " [0.80464435 1.3991406 ]]\n",
      "gb1:  [[-2.8002806]\n",
      " [-1.8574532]]\n",
      "gw2:  [[-1.7143214  6.345569 ]]\n",
      "gb2:  [[-12.679347]]\n"
     ]
    }
   ],
   "source": [
    "print(\"gw1: \", gw1.numpy(), end=\"\\n\")\n",
    "print(\"gb1: \", gb1.numpy(), end=\"\\n\")\n",
    "print(\"gw2: \", gw2.numpy(), end=\"\\n\")\n",
    "print(\"gb2: \", gb2.numpy(), end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "178b9d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before w1:  [[0.06603587 0.7684941 ]\n",
      " [0.3427595  0.84697306]]\n",
      "Before b1:  [[0.7426864 ]\n",
      " [0.28600645]]\n",
      "Before w2:  [[0.22085369 0.14649439]]\n",
      "Before b2:  [[0.01806629]]\n",
      "After w1:  [[0.05390512 0.7474008 ]\n",
      " [0.33471304 0.83298165]]\n",
      "After b1:  [[0.7706892]\n",
      " [0.304581 ]]\n",
      "After w2:  [[0.2379969 0.0830387]]\n",
      "After b2:  [[0.14485976]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Before w1: \", w1.numpy(), end=\"\\n\")\n",
    "print(\"Before b1: \", b1.numpy(), end=\"\\n\")\n",
    "print(\"Before w2: \", w2.numpy(), end=\"\\n\")\n",
    "print(\"Before b2: \", b2.numpy(), end=\"\\n\")\n",
    "\n",
    "    w1.assign_sub(gw1*lr)\n",
    "    b1.assign_sub(gb1*lr)\n",
    "    w2.assign_sub(gw2*lr)\n",
    "    b2.assign_sub(gb2*lr)\n",
    "\n",
    "    print(\"After w1: \", w1.numpy(), end=\"\\n\")\n",
    "    print(\"After b1: \", b1.numpy(), end=\"\\n\")\n",
    "    print(\"After w2: \", w2.numpy(), end=\"\\n\")\n",
    "    print(\"After b2: \", b2.numpy(), end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bc114342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_step(x, y, w1, b1, w2, b2):\n",
    "    y_actual = y\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = forward_prop(x, w1, b1, w2, b2)\n",
    "        \n",
    "        loss = 0.5 * (y_actual - y_pred) ** 2 \n",
    "        \n",
    "    #Gradient Calculation\n",
    "    print(\"**********************************\")\n",
    "    print(\"Gradients\")\n",
    "    print(\"**********************************\")\n",
    "    \n",
    "    gw1, gb1, gw2, gb2 = tape.gradient(loss, [w1, b1, w2, b2])\n",
    "    print(\"The gradient of 1st layer weights are \", gw1.numpy(), end=\"\\n\")\n",
    "    print(\"--------------------------------------\")\n",
    "    print(\"The gradient of 1st layer bias are: \", gb1.numpy(), end=\"\\n\")\n",
    "    print(\"--------------------------------------\")\n",
    "    print(\"The gradient of 2nd layer weights are: \", gw2.numpy(), end=\"\\n\")\n",
    "    print(\"--------------------------------------\")\n",
    "    print(\"The gradient of 2nd layer bias are: \", gb2.numpy(), end=\"\\n\")\n",
    "    print(\"--------------------------------------\")\n",
    "    \n",
    "    #Gradient descent\n",
    "    lr = 0.2\n",
    "    w1.assign_sub(gw1*lr)\n",
    "    b1.assign_sub(gb1*lr)\n",
    "    w2.assign_sub(gw2*lr)\n",
    "    b2.assign_sub(gb2*lr)\n",
    "    \n",
    "    print(\"**********************************\")\n",
    "    print(\"New Updates\")\n",
    "    print(\"**********************************\")\n",
    "\n",
    "    print(\"The updated 1st layer weights are : \", w1.numpy(), end=\"\\n\")\n",
    "    print(\"--------------------------------------\")\n",
    "    print(\"The updated 1st layer bias are:: \", b1.numpy(), end=\"\\n\")\n",
    "    print(\"--------------------------------------\")\n",
    "    print(\"The updated 2nd layer weights are: \", w2.numpy(), end=\"\\n\")\n",
    "    print(\"--------------------------------------\")\n",
    "    print(\"The updated 2nd layer bias are:: \", b2.numpy(), end=\"\\n\")\n",
    "    print(\"--------------------------------------\")\n",
    "    \n",
    "    return w1, b1, w2, b2, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ecf68e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "Gradients\n",
      "**********************************\n",
      "The gradient of 1st layer weights are  [[1.7566408 3.0545015]\n",
      " [1.9066216 3.3152928]]\n",
      "--------------------------------------\n",
      "The gradient of 1st layer bias are:  [[-4.055056]\n",
      " [-4.401274]]\n",
      "--------------------------------------\n",
      "The gradient of 2nd layer weights are:  [[-3.2316666  7.3701825]]\n",
      "--------------------------------------\n",
      "The gradient of 2nd layer bias are:  [[-12.175979]]\n",
      "--------------------------------------\n",
      "**********************************\n",
      "New Updates\n",
      "**********************************\n",
      "The updated 1st layer weights are :  [[ 0.47523126 -0.19249994]\n",
      " [ 0.61551857 -0.24311453]]\n",
      "--------------------------------------\n",
      "The updated 1st layer bias are::  [[1.7496514]\n",
      " [1.0231057]]\n",
      "--------------------------------------\n",
      "The updated 2nd layer weights are:  [[ 0.9793707 -1.1125647]]\n",
      "--------------------------------------\n",
      "The updated 2nd layer bias are::  [[3.0435834]]\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "w1, b1, w2, b2 = init_random_weight()\n",
    "w1, b1, w2, b2, loss = train_one_step(x, y, w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c610eacb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
