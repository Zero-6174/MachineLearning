{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXsu8MxUVAKT"
   },
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kXr4Cxh2VAKZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Eq-7JCT6VAKa"
   },
   "outputs": [],
   "source": [
    "import spacy \n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp=spacy.load('en_core_web_sm',disable=['parser','ner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItxQ587VVAKb"
   },
   "source": [
    "### Read reviews data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "q1pr6bbsVAKb"
   },
   "outputs": [],
   "source": [
    "# Load the Samsung.txt dataset\n",
    "con=open(\"../Dataset/Samsung.txt\",'r', encoding=\"utf-8\")\n",
    "samsung_reviews=con.read()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "f4GyRJMEVAKb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46355"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samsung_reviews.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fU4ZvurwVAKc"
   },
   "source": [
    "### Dataset is a text file where each review is in a new line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "bPT-wYC2VAKd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I feel so LUCKY to have found this used (phone to us & not used hard at all), phone on line from someone who upgraded and sold this one. My Son liked his old one that finally fell apart after 2.5+ years and didn't want an upgrade!! Thank you Seller, we really appreciate it & your honesty re: said used phone.I recommend this seller very highly & would but from them again!!\",\n",
       " 'nice phone, nice up grade from my pantach revue. Very clean set up and easy set up. never had an android phone but they are fantastic to say the least. perfect size for surfing and social media. great phone samsung',\n",
       " 'Very pleased',\n",
       " 'It works good but it goes slow sometimes but its a very good phone I love it']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samsung_reviews.split(\"\\n\")[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUi5gE7WVAKd"
   },
   "source": [
    "### Will our hypothesis hold on real world data? `Product features---POS_NOUN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46355/46355 [02:12<00:00, 350.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "phone      43507\n",
       "battery     4334\n",
       "product     3992\n",
       "screen      3838\n",
       "time        3810\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "nouns = []\n",
    "for review in tqdm(samsung_reviews.split(\"\\n\")[0:46355]):\n",
    "    doc = nlp(review)\n",
    "    for tok in doc:\n",
    "        if tok.pos_ == \"NOUN\":\n",
    "            nouns.append(tok.lemma_.lower())\n",
    "\n",
    "pd.Series(nouns).value_counts().head()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKt6ZNPnVAKg"
   },
   "source": [
    "### Lets do nlp parse on part of one review in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "gOCZxFp_VAKh"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.doc.Doc' object has no attribute 'pos_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m text \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tok \u001b[38;5;129;01min\u001b[39;00m review100:\n\u001b[0;32m----> 6\u001b[0m     pos\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtok\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_\u001b[49m)\n\u001b[1;32m      7\u001b[0m     lemma\u001b[38;5;241m.\u001b[39mappend(tok\u001b[38;5;241m.\u001b[39mlemma_)\n\u001b[1;32m      8\u001b[0m     text\u001b[38;5;241m.\u001b[39mappend(tok\u001b[38;5;241m.\u001b[39mtext)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.doc.Doc' object has no attribute 'pos_'"
     ]
    }
   ],
   "source": [
    "# Convert each token into its lemma and identify the PoS tags.\n",
    "pos = []\n",
    "lemma = []\n",
    "text = []\n",
    "for tok in review100:\n",
    "    pos.append(tok.pos_)\n",
    "    lemma.append(tok.lemma_)\n",
    "    text.append(tok.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feel</td>\n",
       "      <td>feel</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>so</td>\n",
       "      <td>so</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LUCKY</td>\n",
       "      <td>LUCKY</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text  lemma   pos\n",
       "0      I      I  PRON\n",
       "1   feel   feel  VERB\n",
       "2     so     so   ADV\n",
       "3  LUCKY  LUCKY  NOUN\n",
       "4     to     to  PART"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_table = pd.DataFrame({'text':text,'lemma':lemma,'pos':pos})\n",
    "nlp_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOBlgcu0VAKh"
   },
   "source": [
    "#### Real world data is usually messy, observe the words `found` and `used`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "yB1t1bPTVAKh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     lemma    pos \n",
       "phone    phone    NOUN    3\n",
       "one      one      NOUN    2\n",
       "LUCKY    LUCKY    NOUN    1\n",
       "honesty  honesty  NOUN    1\n",
       "line     line     NOUN    1\n",
       "re       re       NOUN    1\n",
       "seller   seller   NOUN    1\n",
       "upgrade  upgrade  NOUN    1\n",
       "years    year     NOUN    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_table[nlp_table.pos == 'NOUN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3LDkWepVAKi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FEXKFzlPVAKi"
   },
   "outputs": [],
   "source": [
    "## Get most frequent lemma forms of nouns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-uR8q-LVAKi"
   },
   "source": [
    "#### It seems possible that if we extract all the nouns from the reviews and look at the top 5 most frequent lemmatised noun forms, we will be able to identify `What people are talking about?`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOvqBuwgVAKj"
   },
   "source": [
    "### Lets repeat this experiment on a larger set of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RsDUv3X1VAKj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrVi3UPTVAKj"
   },
   "source": [
    "### Lets add some way of keeping track of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zNhp_45EVAKj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jai2hnfoVAKk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94gZ5gxLVAKk"
   },
   "source": [
    "### Did you notice anything? What do you think will be the time taken to process all the reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Op_ftvWyVAKk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VDMknUOXVAKl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PsJmzrtVAKl"
   },
   "source": [
    "## Summary\n",
    "- POS tag based rule seems to be working well\n",
    "- We need to figure out a way to reduce the time taken to process reviews"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "POS2_Commented.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
